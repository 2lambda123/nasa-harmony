apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups: [""]
  resources:
  - nodes
  - nodes/proxy
  - services
  - endpoints
  - pods
  verbs: ["get", "list", "watch"]
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs: ["get", "list", "watch"]
- nonResourceURLs: ["/metrics"]
  verbs: ["get"]
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: monitoring
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: monitoring
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  # for Go template variables that shouldn't be replaced by envsubst, use 'ยง' prefix instead of '$'
  # 'ยง' will be replaced with '$' after running envsubst but before passing the yaml to kubectl
  prometheus.rules: |-
    groups:
    - name: default
      rules:
      - alert: KubernetesPodNotHealthy
        expr: min_over_time(sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"})[$PROMETHEUS_POD_NOT_HEALTHY_DURATION:1m]) > 0
        for: 0m
        labels:
          environment: $CLIENT_ID
          duration: $PROMETHEUS_POD_NOT_HEALTHY_DURATION
        annotations:
          summary: "AlertManager has detected pod(s) in a non-ready phase (Pending|Unknown|Failed)."
      - alert: KubernetesNodeNotReady
        expr: kube_node_status_condition{condition="Ready",status="true"} == 0
        for: $PROMETHEUS_NODE_NOT_READY_DURATION
        labels:
          environment: $CLIENT_ID
          duration: $PROMETHEUS_NODE_NOT_READY_DURATION
        annotations:
          summary: "AlertManager has detected Node(s) in an unready state."
  prometheus.yml: |
    global:
      scrape_interval:     15s
    rule_files:
      - /etc/prometheus/prometheus.rules
    alerting:
      alertmanagers:
        - static_configs:
            - targets:
                - "alertmanager:9093"
    scrape_configs:
      - job_name: 'prometheus'
        scrape_interval: $PROMETHEUS_PROMETHEUS_SCRAPE_INTERVAL
        static_configs:
          - targets: ['localhost:9090']
      - job_name: 'pod-manager'
        scrape_interval: $PROMETHEUS_POD_MANAGER_SCRAPE_INTERVAL
        kubernetes_sd_configs:
        - role: pod
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: kubernetes_namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: kubernetes_pod_name
      - job_name: 'kube-state-metrics'
        static_configs: 
        - targets: ['kube-state-metrics:8080']
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: monitoring
  labels:
    app: prometheus
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      containers:
      - name: prometheus
        image: quay.io/prometheus/prometheus:v2.33.1
        imagePullPolicy: IfNotPresent
        resources:
          requests:
            ephemeral-storage: $PROMETHEUS_REQUESTS_EPHEMERAL_STORAGE
            memory: $PROMETHEUS_REQUESTS_MEMORY
            cpu: $PROMETHEUS_REQUESTS_CPU
          limits:
            ephemeral-storage: $PROMETHEUS_LIMITS_EPHEMERAL_STORAGE
            memory: $PROMETHEUS_LIMITS_MEMORY
            cpu: $PROMETHEUS_LIMITS_CPU
        args:
          - '--storage.tsdb.retention=6h'
          - '--storage.tsdb.path=/prometheus'
          - '--config.file=/etc/prometheus/prometheus.yml'
        command:
        - /bin/prometheus
        ports:
        - name: web
          containerPort: 9090
        volumeMounts:
        - name: config-volume
          mountPath: /etc/prometheus
        - name: data
          mountPath: /prometheus
      restartPolicy: Always
      securityContext: {}
      terminationGracePeriodSeconds: 30
      volumes:
      - name: config-volume
        configMap:
          name: prometheus-config
      - name: data
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: prometheus
  name: prometheus
  namespace: monitoring
spec:
  selector:
    app: prometheus
  ports:
    - protocol: TCP
      port: 9090
      targetPort: 9090
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: alertmanager-config
  namespace: monitoring
data:
  config.yml: |-
    global:
    templates:
      - '/etc/alertmanager/*.tmpl'
    route:
      receiver: default
      group_by: [alertname]
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 2h
      routes:
    receivers:
      - name: 'default'
        sns_configs:
        - topic_arn: $PROMETHEUS_ALERTS_ARN
          subject: '[Alert Manager $CLIENT_ID] {{ .GroupLabels.alertname }}'
          sigv4:
            region: $AWS_DEFAULT_REGION
            access_key: $AWS_ACCESS_KEY_ID
            secret_key: $AWS_SECRET_ACCESS_KEY
---
apiVersion: v1
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: alertmanager-templates
  namespace: monitoring
data:
  default.tmpl: |
    template
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      name: alertmanager
      labels:
        app: alertmanager
    spec:
      containers:
      - name: alertmanager
        image: prom/alertmanager:latest
        args:
          - "--config.file=/etc/alertmanager/config.yml"
          - "--storage.path=/alertmanager"
        ports:
        - name: alertmanager
          containerPort: 9093
        resources:
            requests:
              memory: $PROMETHEUS_ALERT_MANAGER_REQUESTS_MEMORY
              cpu: $PROMETHEUS_ALERT_MANAGER_REQUESTS_CPU
            limits:
              memory: $PROMETHEUS_ALERT_MANAGER_LIMITS_MEMORY
              cpu: $PROMETHEUS_ALERT_MANAGER_LIMITS_CPU
        volumeMounts:
        - name: config-volume
          mountPath: /etc/alertmanager
        - name: templates-volume
          mountPath: /etc/alertmanager-templates
        - name: alertmanager
          mountPath: /alertmanager
      volumes:
      - name: config-volume
        configMap:
          name: alertmanager-config
      - name: templates-volume
        configMap:
          name: alertmanager-templates
      - name: alertmanager
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  selector:
    app: alertmanager
  ports:
    - protocol: TCP
      port: 9093
      targetPort: 9093