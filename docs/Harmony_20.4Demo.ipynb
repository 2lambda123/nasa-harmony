{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harmony Service Chaining: PI 20.4 Demo\n",
    "\n",
    "In PI 20.4, Harmony add service chaining capabilities to support requests that require functionality beyond that of a single service.\n",
    "This notebook provides a basic workflow to demonstrate service chaining. For more a general introduction and tutorial, see [Harmony API Introduction](./Harmony%20Api%20Introduction.ipynb).  Useful helpers for making the calls found in this notebook can be found under the [docs/notebook-helpers](./notebook-helpers) folder.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. Install Python 3. This notebook is tested to work in 3.8 but should work in most recent 3.x versions.\n",
    "2. Install Jupyter: pip install jupyterlab\n",
    "3. Setup your ~/.netrc for Earthdata Login as described in Harmony API Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up AWS\n",
    "\n",
    "Once you have Zarr links, you can access them with your AWS credentials to the Harmony account.  Obtain the credentials and make sure your default AWS account uses them.  One way to do this is to edit `~/.aws/credentials` to have the following section:\n",
    "```\n",
    "[default]\n",
    "aws_access_key_id = YOUR_HARMONY_ACCESS_KEY_ID\n",
    "aws_secret_access_key = YOUR_HARMONY_SECRET_ACCESS_KEY\n",
    "```\n",
    "Restart your Jupyter kernel after completing this step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports and Earthdata Login\n",
    "\n",
    "We need to set up general-purpose imports and authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%matplotlib inline\n",
    "import sys\n",
    "# Install dependencies into the Jupyter Kernel\n",
    "!{sys.executable} -m pip install -q -r notebook_helpers/requirements.txt\n",
    "!{sys.executable} -m pip install rasterio boto3 s3fs zarr\n",
    "\n",
    "# Import libraries used throughout the notebook\n",
    "from urllib import request, parse\n",
    "from http.cookiejar import CookieJar\n",
    "import getpass\n",
    "import netrc\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from notebook_helpers import get, post, show, get_data_urls, show_async, show_async_condensed, show_shape, print_async_status, check_bbox_subset, check_stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_earthdata_login_auth(endpoint):\n",
    "    \"\"\"\n",
    "    Set up the request library so that it authenticates against the given Earthdata Login\n",
    "    endpoint and is able to track cookies between requests.  This looks in the .netrc file \n",
    "    first and if no credentials are found, it prompts for them.\n",
    "\n",
    "    Valid endpoints include:\n",
    "        uat.urs.earthdata.nasa.gov - Earthdata Login UAT (Harmony's current default)\n",
    "        urs.earthdata.nasa.gov - Earthdata Login production\n",
    "    \"\"\"\n",
    "    try:\n",
    "        username, _, password = netrc.netrc().authenticators(endpoint)\n",
    "    except (FileNotFoundError, TypeError):\n",
    "        # FileNotFound = There's no .netrc file\n",
    "        # TypeError = The endpoint isn't in the netrc file, causing the above to try unpacking None\n",
    "        print('Please provide your Earthdata Login credentials to allow data access')\n",
    "        print('Your credentials will only be passed to %s and will not be exposed in Jupyter' % (endpoint))\n",
    "        username = input('Username:')\n",
    "        password = getpass.getpass()\n",
    "\n",
    "    manager = request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    manager.add_password(None, endpoint, username, password)\n",
    "    auth = request.HTTPBasicAuthHandler(manager)\n",
    "\n",
    "    jar = CookieJar()\n",
    "    processor = request.HTTPCookieProcessor(jar)\n",
    "    opener = request.build_opener(auth, processor)\n",
    "    request.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_earthdata_login_auth('uat.urs.earthdata.nasa.gov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chained Services - PODAAC L1 Subsetter -> Harmony NetCDF to Zarr\n",
    "\n",
    "This request asks for variable subsetting of L1 data with output in the Zarr format. This requires chaining two services together, the PODAAC L1 Subsetter and the Harmony NetCDF to Zarr service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmony_collection_id = 'C1234208438-POCLOUD'\n",
    "coverages_root = 'https://harmony.sit.earthdata.nasa.gov/{collection}/ogc-api-coverages/1.0.0/collections/{variable}/coverage/rangeset'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable and spatial subsetting with reformtatting output to Zarr and spatial constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "harmony_root = 'https://harmony.sit.earthdata.nasa.gov'\n",
    "asyncConfig = {\n",
    "    'collection_id': harmony_collection_id,\n",
    "    'ogc-api-coverages_version': '1.0.0',\n",
    "    'variable': 'mean_sea_surface',\n",
    "    'maxResults': '2',\n",
    "    'format': 'application/x-zarr'\n",
    "}\n",
    "\n",
    "async_url = harmony_root+'/{collection_id}/ogc-api-coverages/{ogc-api-coverages_version}/collections/{variable}/coverage/rangeset?subset=lon(-160%3A-160)&subset=lat(-80%3A80)&maxResults={maxResults}&format={format}'.format(**asyncConfig)\n",
    "print('Request URL', async_url)\n",
    "async_response = request.urlopen(async_url)\n",
    "async_results = async_response.read()\n",
    "async_json = json.loads(async_results)\n",
    "pprint.pprint(async_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_url = harmony_root + '/jobs/' + async_json['jobID']\n",
    "\n",
    "#Continue loop while request is still processing\n",
    "while True:\n",
    "    loop_response = request.urlopen(job_url)\n",
    "    loop_results = loop_response.read()\n",
    "    job_json = json.loads(loop_results)\n",
    "    if job_json['status'] != 'running':\n",
    "        break\n",
    "    print('Job status is running. Progress is ', job_json['progress'], '%. Trying again.')\n",
    "    time.sleep(5)\n",
    "\n",
    "links = []\n",
    "if job_json['status'] == 'successful' and job_json['progress'] == 100:\n",
    "    print('Job progress is 100%. Output links printed below:')\n",
    "    links = [link['href'] for link in job_json['links'] if link.get('rel', 'data') == 'data']\n",
    "    print('\\n'.join(links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the Zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import zarr\n",
    "\n",
    "# older versions of s3fs\n",
    "# fs = s3fs.S3FileSystem(region_name='us-west-2')\n",
    "\n",
    "# import botocore\n",
    "# client_session = botocore.session.Session(profile='NON-DEFAULT-PROFILE')\n",
    "# fs = s3fs.S3FileSystem(session=client_session, client_kwargs={'region_name':'us-west-2'})\n",
    "\n",
    "fs = s3fs.S3FileSystem(client_kwargs={'region_name':'us-west-2'})\n",
    "\n",
    "store = fs.get_mapper(root=links[0], check=False)\n",
    "zarr_file = zarr.open(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zarr_file.tree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(zarr_file['mean_sea_surface']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
